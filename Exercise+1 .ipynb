{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1 : Fraudulent Transactions (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Exercise\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\Exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fraud = pd.read_csv('fraud_prep.csv')# reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin some exploratory data analysis! We'll start by checking out missing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "fraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Data.\n",
    "We can use seaborn to create a simple heatmap to see where we are missing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2158adcd4a8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAANvCAYAAADEFauAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2158addf940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(fraud.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see in this heatmap there is no horizental yellow line which meen we do not have any missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fraud.drop('Class',axis=1), \n",
    "                                                    fraud['Class'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation.\n",
    "We can check precision,recall,f1-score using classification report and confiusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85299\n",
      "          1       0.82      0.60      0.69       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "/n\n",
      "[[85280    19]\n",
      " [   58    86]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"/n\")\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-flod cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular resampling technique is k-fold cross validation. It allows us to train and test our model k-times on different subsets of training data and build up an estimate of the performance of a machine learning model on unseen data.The accuracies measures help us to understand the ability of generalisation for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998976746655\n",
      "/n\n",
      "8.74474055643e-05\n"
     ]
    }
   ],
   "source": [
    "#K-flod cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = logmodel, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print('/n')\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start just by training a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and Evaluation.\n",
    "Let's evaluate our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85299\n",
      "          1       0.71      0.74      0.73       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85255    44]\n",
      " [   37   107]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999127228196\n",
      "/n\n",
      "0.000145702506698\n"
     ]
    }
   ],
   "source": [
    "#K-flod cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = dtree, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print('/n')\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now let's compare the decision tree model to a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85292     7]\n",
      " [   28   116]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85299\n",
      "          1       0.94      0.81      0.87       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for n_estimators=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[85292     7]\n",
    " [   30   114]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       1.00      1.00      1.00     85299\n",
    "          1       0.94      0.79      0.86       144\n",
    "\n",
    "avg / total       1.00      1.00      1.00     85443\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999513453584\n",
      "/n\n",
      "9.79021224335e-05\n"
     ]
    }
   ],
   "source": [
    "#K-flod cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print('/n')\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(fraud.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(fraud.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         V7        V8        V9    ...          V20       V21       V22  \\\n",
       "0  0.193679  0.082637  0.331128    ...     0.326118 -0.024923  0.382854   \n",
       "1 -0.063700  0.071253 -0.232494    ...    -0.089611 -0.307377 -0.880077   \n",
       "2  0.639776  0.207373 -1.378675    ...     0.680975  0.337632  1.063358   \n",
       "3  0.192071  0.316018 -1.262503    ...    -0.269855 -0.147443  0.007267   \n",
       "4  0.479302 -0.226510  0.744326    ...     0.529939 -0.012839  1.100011   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28    Amount  \n",
       "0 -0.176911  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1  0.162201 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2  1.456320 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -0.304777 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4 -0.220123  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_feat = pd.DataFrame(scaled_features,columns=fraud.columns[:-1])\n",
    "fraud_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,fraud['Class'],\n",
    "                                                    test_size=0.30,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) # We'll start with k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our KNN model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85277    22]\n",
      " [   28   116]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85299\n",
      "          1       0.84      0.81      0.82       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a K Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the elbow method to pick a good K Value.By choosing different k value we calculate the error rate of the model.We choose the first K value which seems to have minimum error rate by using elbow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,5):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1bb60729518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoQAAAGDCAYAAACyWgFqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsDmFEABgcwohAMDmFEIAgM0phAAAm/sOvnL4BWfnijUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb606f30b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,5),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=3\n",
      "\n",
      "\n",
      "[[85290     9]\n",
      " [   27   117]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85299\n",
      "          1       0.93      0.81      0.87       144\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOW WITH K=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print('WITH K=3')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998389880469\n",
      "/n\n",
      "8.22546705754e-05\n"
     ]
    }
   ],
   "source": [
    "#K-flod cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print('/n')\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to come back to our original data which is not scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = pd.read_csv('fraud_prep.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fraud.drop('Class',axis=1), \n",
    "                                                    fraud['Class'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[85299     0]\n",
    " [  139     5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       1.00      1.00      1.00     85299\n",
    "          1       1.00      0.03      0.07       144\n",
    "\n",
    "avg / total       1.00      1.00      1.00     85443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT so good results!!.We can just classify one class by this model.So we need to adjuste the parameters.We can search for parameters using a GridSearch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the right parameters (like what C or gamma values to use) will take time, we can just try a bunch of combinations and see what works best! \n",
    "GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.My undrestanding (for the above SVM it takes me 2 hour to get the result) it is costy for any large datasets, so I put the codes here which I executed for smaller problems without any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3) # verbose just means the text output describing the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))\n",
    "print('/n')\n",
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fraud.drop('Class',axis=1), \n",
    "                                                    fraud['Class'], test_size=0.30, \n",
    "                                                    random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix and classfication report\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[85299,     0],\n",
    " [  144,     0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       1.00      1.00      1.00     85299\n",
    "          1       0.00      0.00      0.00       144\n",
    "\n",
    "avg / total       1.00      1.00      1.00     85443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have better performance for ANN we need to do Gridsearch by trying some parameters for input_dim and activation function as we have done for SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the KNN (k =3,f1-score: 1,0.87) and Random forest (f1-score: 1,0.86) models have better performances.\n",
    "Trying to grid search for SVM and ANN will take time.But by doing this search for these models it is possible to find a good model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS Points : Can you think of some unsupervised methods to accomplish this same task? If so, describe them (do not script them) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:I think we can use K Means Clustering model to do unsupervised classification without looking at the Class column in our data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
